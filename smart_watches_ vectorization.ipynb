{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e414043f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35681744",
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_df=pd.read_csv(\"/home/futures/smart_watches_amazon.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfc1bb69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Style</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Screen Size</th>\n",
       "      <th>Special Feature</th>\n",
       "      <th>Target Audience</th>\n",
       "      <th>Series</th>\n",
       "      <th>Age Range (Description)</th>\n",
       "      <th>Shape</th>\n",
       "      <th>Item Dimensions LxWxH</th>\n",
       "      <th>Item Weight</th>\n",
       "      <th>Battery Life</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.83 Inches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fire-Boltt Phoenix Smart Watch with Bluetooth ...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.3 Inches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Smart Watch Dual Chi...</td>\n",
       "      <td>1,449</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire-Boltt Ninja 3 Smartwatch Full Touch 1.69 ...</td>\n",
       "      <td>1,299</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja 3</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Pink</td>\n",
       "      <td>1.83 Inches</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  price       Brand  \\\n",
       "0  Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...  1,799  Fire-Boltt   \n",
       "1  Fire-Boltt Phoenix Smart Watch with Bluetooth ...  1,799  Fire-Boltt   \n",
       "2  Fire-Boltt Ninja Call Pro Smart Watch Dual Chi...  1,449  Fire-Boltt   \n",
       "3  Fire-Boltt Ninja 3 Smartwatch Full Touch 1.69 ...  1,299  Fire-Boltt   \n",
       "4  Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...  1,799  Fire-Boltt   \n",
       "\n",
       "       Model Name   Style Colour  Screen Size Special Feature Target Audience  \\\n",
       "0  Ninja Call Pro  Modern  Black  1.83 Inches             NaN             NaN   \n",
       "1             NaN  Modern  Black   1.3 Inches             NaN             NaN   \n",
       "2  Ninja Call Pro  Modern  Black  1.69 Inches             NaN             NaN   \n",
       "3         Ninja 3  Modern  Black  1.69 Inches             NaN             NaN   \n",
       "4  Ninja Call Pro  Modern   Pink  1.83 Inches             NaN             NaN   \n",
       "\n",
       "  Series Age Range (Description) Shape Item Dimensions LxWxH Item Weight  \\\n",
       "0    NaN                     NaN   NaN                   NaN         NaN   \n",
       "1    NaN                     NaN   NaN                   NaN         NaN   \n",
       "2    NaN                     NaN   NaN                   NaN         NaN   \n",
       "3    NaN                     NaN   NaN                   NaN         NaN   \n",
       "4    NaN                     NaN   NaN                   NaN         NaN   \n",
       "\n",
       "  Battery Life  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfa6bfef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Style</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Screen Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.83 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fire-Boltt Phoenix Smart Watch with Bluetooth ...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.3 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Smart Watch Dual Chi...</td>\n",
       "      <td>1,449</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fire-Boltt Ninja 3 Smartwatch Full Touch 1.69 ...</td>\n",
       "      <td>1,299</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja 3</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Pink</td>\n",
       "      <td>1.83 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>Fire-Boltt Phoenix Smart Watch with Bluetooth ...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.3 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>Noise Pulse Go Buzz Bluetooth Calling Smart Wa...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Noise</td>\n",
       "      <td>ColorFit Pulse Go Buzz</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>Noise ColorFit Pulse Grand Smart Watch with 1....</td>\n",
       "      <td>1,299</td>\n",
       "      <td>Noise</td>\n",
       "      <td>ColorFit Grand</td>\n",
       "      <td>ColorFit Pulse Grand</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>boAt Xtend/Xtend RTL Smartwatch with Alexa Bui...</td>\n",
       "      <td>2,299</td>\n",
       "      <td>BoAt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>With Alexa</td>\n",
       "      <td>Sandy Cream</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2315</th>\n",
       "      <td>Fire-Boltt Ninja Call Pro Smart Watch Dual Chi...</td>\n",
       "      <td>1,799</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>Ninja Call Pro</td>\n",
       "      <td>Modern</td>\n",
       "      <td>Black</td>\n",
       "      <td>1.69 Inches</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2316 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Name  price       Brand  \\\n",
       "0     Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...  1,799  Fire-Boltt   \n",
       "1     Fire-Boltt Phoenix Smart Watch with Bluetooth ...  1,799  Fire-Boltt   \n",
       "2     Fire-Boltt Ninja Call Pro Smart Watch Dual Chi...  1,449  Fire-Boltt   \n",
       "3     Fire-Boltt Ninja 3 Smartwatch Full Touch 1.69 ...  1,299  Fire-Boltt   \n",
       "4     Fire-Boltt Ninja Call Pro Plus 1.83\" Smart Wat...  1,799  Fire-Boltt   \n",
       "...                                                 ...    ...         ...   \n",
       "2311  Fire-Boltt Phoenix Smart Watch with Bluetooth ...  1,799  Fire-Boltt   \n",
       "2312  Noise Pulse Go Buzz Bluetooth Calling Smart Wa...  1,799       Noise   \n",
       "2313  Noise ColorFit Pulse Grand Smart Watch with 1....  1,299       Noise   \n",
       "2314  boAt Xtend/Xtend RTL Smartwatch with Alexa Bui...  2,299        BoAt   \n",
       "2315  Fire-Boltt Ninja Call Pro Smart Watch Dual Chi...  1,799  Fire-Boltt   \n",
       "\n",
       "                  Model Name                 Style       Colour  Screen Size  \n",
       "0             Ninja Call Pro                Modern        Black  1.83 Inches  \n",
       "1                        NaN                Modern        Black   1.3 Inches  \n",
       "2             Ninja Call Pro                Modern        Black  1.69 Inches  \n",
       "3                    Ninja 3                Modern        Black  1.69 Inches  \n",
       "4             Ninja Call Pro                Modern         Pink  1.83 Inches  \n",
       "...                      ...                   ...          ...          ...  \n",
       "2311                     NaN                Modern        Black   1.3 Inches  \n",
       "2312  ColorFit Pulse Go Buzz                Modern        Black  1.69 Inches  \n",
       "2313          ColorFit Grand  ColorFit Pulse Grand        Black  1.69 Inches  \n",
       "2314                     NaN            With Alexa  Sandy Cream          NaN  \n",
       "2315          Ninja Call Pro                Modern        Black  1.69 Inches  \n",
       "\n",
       "[2316 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df.drop(['Special Feature','Target Audience','Series','Age Range (Description)','Shape','Item Dimensions LxWxH','Item Weight','Battery Life'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "596bd1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Fire-Boltt', 'Noise', 'BoAt', 'CrossBeats', 'Samsung',\n",
       "       'ZEBRONICS', 'Fastrack', 'TAGG', 'Apple', 'Fitbit', 'Titan'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_df[\"Brand\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35314a36",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_5851/2256587446.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'paraphrase-MiniLM-L6-v2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b9133169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers<5.0.0,>=4.6.0\n",
      "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm in ./desktop/lib/python3.9/site-packages (from sentence_transformers) (4.64.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-1.13.1-cp39-cp39-manylinux1_x86_64.whl (887.4 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.4/887.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.14.1-cp39-cp39-manylinux1_x86_64.whl (24.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m41.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy in ./desktop/lib/python3.9/site-packages (from sentence_transformers) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn in ./desktop/lib/python3.9/site-packages (from sentence_transformers) (1.0.2)\n",
      "Requirement already satisfied: scipy in ./desktop/lib/python3.9/site-packages (from sentence_transformers) (1.9.1)\n",
      "Requirement already satisfied: nltk in ./desktop/lib/python3.9/site-packages (from sentence_transformers) (3.7)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m52.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub>=0.4.0\n",
      "  Downloading huggingface_hub-0.12.0-py3-none-any.whl (190 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in ./desktop/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.9 in ./desktop/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./desktop/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.3.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./desktop/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: filelock in ./desktop/lib/python3.9/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.6.0)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in ./desktop/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (63.4.1)\n",
      "Requirement already satisfied: wheel in ./desktop/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.6.0->sentence_transformers) (0.37.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./desktop/lib/python3.9/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "  Downloading tokenizers-0.13.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib in ./desktop/lib/python3.9/site-packages (from nltk->sentence_transformers) (1.1.0)\n",
      "Requirement already satisfied: click in ./desktop/lib/python3.9/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./desktop/lib/python3.9/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./desktop/lib/python3.9/site-packages (from torchvision->sentence_transformers) (9.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./desktop/lib/python3.9/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence_transformers) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./desktop/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./desktop/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./desktop/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./desktop/lib/python3.9/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2022.9.14)\n",
      "Building wheels for collected packages: sentence_transformers\n",
      "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=273258fb180d1163c1bc493fb0a6ffbe3618415f053bf2776ebcf0dda23dc6e6\n",
      "  Stored in directory: /home/futures/.cache/pip/wheels/71/67/06/162a3760c40d74dd40bc855d527008d26341c2b0ecf3e8e11f\n",
      "Successfully built sentence_transformers\n",
      "Installing collected packages: tokenizers, sentencepiece, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, huggingface-hub, transformers, torch, torchvision, sentence_transformers\n",
      "Successfully installed huggingface-hub-0.12.0 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 sentence_transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 torch-1.13.1 torchvision-0.14.1 transformers-4.26.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51d38a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10b8b63fdedc4fba8c48ba88fad73e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/.gitattributes:   0%|          | 0.00/690 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c6e027e5003486aa778830b35f2de4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "260dcd982bf24aa4a2a825112d4e164f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/README.md:   0%|          | 0.00/3.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7629bc12994bf2bef3055bf4a4108a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)bb8001fa/config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1816ddcfb61a468c830c37062abd04b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)ce_transformers.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc04cbeba4904979a475a966acde1fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79de5a5386954aa1936d0e15d02b92e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)nce_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3a2e5be2524f7bab4c2e837c537e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1df07647b9b426793124de3abb2703e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)001fa/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bc0d6610364425af433423588424ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ca96326a3b24d1abd5dd8f5ea484909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)3bbb8001fa/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3a84a222d14d4a8a6832f49ad713f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)b8001fa/modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceaab564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad88073845544ceaaf270d5d1fb70ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf2e7a5300542219424a06e3c53ece0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2670bd126264c51931c2c672256f29f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1352807615aa4a34bb80f29f236535a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42375163",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode_plus([\"Brand\"], add_special_tokens=True, return_tensors='pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7caed8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = bert_model(**inputs)\n",
    "embeddings = outputs.last_hidden_state[:, 0, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41fc6c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained BERT model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=True)\n",
    "\n",
    "# Load the e-commerce dataset\n",
    "data = pd.read_csv(\"/home/futures/smart_watches_amazon.csv\")\n",
    "\n",
    "# Vectorize the e-commerce data using BERT\n",
    "embeddings = []\n",
    "for text in data['Brand']:\n",
    "    inputs = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt')\n",
    "    outputs = bert_model(**inputs)\n",
    "    embedding = outputs.last_hidden_state[:, 0, :].detach().numpy()\n",
    "    embeddings.append(embedding)\n",
    "embeddings = np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce6f615",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
